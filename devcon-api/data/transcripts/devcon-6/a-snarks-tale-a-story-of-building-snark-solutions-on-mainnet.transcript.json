{
	"systeminfo": "AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | ",
	"model": {
		"type": "base",
		"multilingual": false,
		"vocab": 51864,
		"audio": {
			"ctx": 1500,
			"state": 512,
			"head": 8,
			"layer": 6
		},
		"text": {
			"ctx": 448,
			"state": 512,
			"head": 8,
			"layer": 6
		},
		"mels": 80,
		"f16": 1
	},
	"params": {
		"model": "models/ggml-base.en.bin",
		"language": "en",
		"translate": false
	},
	"result": {
		"language": "en"
	},
	"transcription": [
		{
			"timestamps": {
				"from": "00:00:00,000",
				"to": "00:00:15,000"
			},
			"offsets": {
				"from": 0,
				"to": 15000
			},
			"text": " [Music]"
		},
		{
			"timestamps": {
				"from": "00:00:15,000",
				"to": "00:00:17,000"
			},
			"offsets": {
				"from": 15000,
				"to": 17000
			},
			"text": " Hey everybody."
		},
		{
			"timestamps": {
				"from": "00:00:17,000",
				"to": "00:00:21,000"
			},
			"offsets": {
				"from": 17000,
				"to": 21000
			},
			"text": " So the next talk is going to start in a bit."
		},
		{
			"timestamps": {
				"from": "00:00:21,000",
				"to": "00:00:24,000"
			},
			"offsets": {
				"from": 21000,
				"to": 24000
			},
			"text": " It's going to be a tale, a snark tale,"
		},
		{
			"timestamps": {
				"from": "00:00:24,000",
				"to": "00:00:27,000"
			},
			"offsets": {
				"from": 24000,
				"to": 27000
			},
			"text": " a story of building snark solutions on the mainnet"
		},
		{
			"timestamps": {
				"from": "00:00:27,000",
				"to": "00:00:31,000"
			},
			"offsets": {
				"from": 27000,
				"to": 31000
			},
			"text": " by savvy, a chord from the graph."
		},
		{
			"timestamps": {
				"from": "00:00:31,000",
				"to": "00:00:33,000"
			},
			"offsets": {
				"from": 31000,
				"to": 33000
			},
			"text": " But before we get ready,"
		},
		{
			"timestamps": {
				"from": "00:00:33,000",
				"to": "00:00:38,000"
			},
			"offsets": {
				"from": 33000,
				"to": 38000
			},
			"text": " does anyone have any interesting snark tale?"
		},
		{
			"timestamps": {
				"from": "00:00:38,000",
				"to": "00:00:47,000"
			},
			"offsets": {
				"from": 38000,
				"to": 47000
			},
			"text": " Do people actually use ZKPs here in any user way?"
		},
		{
			"timestamps": {
				"from": "00:00:47,000",
				"to": "00:00:49,000"
			},
			"offsets": {
				"from": 47000,
				"to": 49000
			},
			"text": " Or is one person? That's nice."
		},
		{
			"timestamps": {
				"from": "00:00:49,000",
				"to": "00:00:52,000"
			},
			"offsets": {
				"from": 49000,
				"to": 52000
			},
			"text": " Could you tell us your snark tale?"
		},
		{
			"timestamps": {
				"from": "00:00:52,000",
				"to": "00:00:54,000"
			},
			"offsets": {
				"from": 52000,
				"to": 54000
			},
			"text": " What is it first time?"
		},
		{
			"timestamps": {
				"from": "00:00:54,000",
				"to": "00:00:57,000"
			},
			"offsets": {
				"from": 54000,
				"to": 57000
			},
			"text": " Just sit back, close your eyes,"
		},
		{
			"timestamps": {
				"from": "00:00:57,000",
				"to": "00:01:00,000"
			},
			"offsets": {
				"from": 57000,
				"to": 60000
			},
			"text": " and tell us about the first time you ever use a snark."
		},
		{
			"timestamps": {
				"from": "00:01:00,000",
				"to": "00:01:02,000"
			},
			"offsets": {
				"from": 60000,
				"to": 62000
			},
			"text": " Oh, he doesn't have a microphone,"
		},
		{
			"timestamps": {
				"from": "00:01:02,000",
				"to": "00:01:05,000"
			},
			"offsets": {
				"from": 62000,
				"to": 65000
			},
			"text": " but I'm going to run there."
		},
		{
			"timestamps": {
				"from": "00:01:05,000",
				"to": "00:01:11,000"
			},
			"offsets": {
				"from": 65000,
				"to": 71000
			},
			"text": " [Music]"
		},
		{
			"timestamps": {
				"from": "00:01:11,000",
				"to": "00:01:14,000"
			},
			"offsets": {
				"from": 71000,
				"to": 74000
			},
			"text": " Well, to send the transaction on the mainnet network,"
		},
		{
			"timestamps": {
				"from": "00:01:14,000",
				"to": "00:01:18,000"
			},
			"offsets": {
				"from": 74000,
				"to": 78000
			},
			"text": " which is a ZK layer one."
		},
		{
			"timestamps": {
				"from": "00:01:18,000",
				"to": "00:01:23,000"
			},
			"offsets": {
				"from": 78000,
				"to": 83000
			},
			"text": " Nice. That was a nice and not push at all shell of mainnet."
		},
		{
			"timestamps": {
				"from": "00:01:23,000",
				"to": "00:01:26,000"
			},
			"offsets": {
				"from": 83000,
				"to": 86000
			},
			"text": " [Laughter]"
		},
		{
			"timestamps": {
				"from": "00:01:26,000",
				"to": "00:01:29,000"
			},
			"offsets": {
				"from": 86000,
				"to": 89000
			},
			"text": " But, yeah, appreciate it. Thank you for sharing."
		},
		{
			"timestamps": {
				"from": "00:01:29,000",
				"to": "00:01:34,000"
			},
			"offsets": {
				"from": 89000,
				"to": 94000
			},
			"text": " So, yeah, finally, please welcome on stage Savvy from the graph."
		},
		{
			"timestamps": {
				"from": "00:01:34,000",
				"to": "00:01:39,000"
			},
			"offsets": {
				"from": 94000,
				"to": 99000
			},
			"text": " [Applause]"
		},
		{
			"timestamps": {
				"from": "00:01:39,000",
				"to": "00:01:41,000"
			},
			"offsets": {
				"from": 99000,
				"to": 101000
			},
			"text": " All right, thank you."
		},
		{
			"timestamps": {
				"from": "00:01:41,000",
				"to": "00:01:43,000"
			},
			"offsets": {
				"from": 101000,
				"to": 103000
			},
			"text": " Yeah, so I'm a cryptographer at Semiotic Labs,"
		},
		{
			"timestamps": {
				"from": "00:01:43,000",
				"to": "00:01:46,000"
			},
			"offsets": {
				"from": 103000,
				"to": 106000
			},
			"text": " and this is a joint work with Jackson Blazensky from Edgenode,"
		},
		{
			"timestamps": {
				"from": "00:01:46,000",
				"to": "00:01:48,000"
			},
			"offsets": {
				"from": 106000,
				"to": 108000
			},
			"text": " except we're core developers from the graph,"
		},
		{
			"timestamps": {
				"from": "00:01:48,000",
				"to": "00:01:50,000"
			},
			"offsets": {
				"from": 108000,
				"to": 110000
			},
			"text": " and basically we're just going to walk through"
		},
		{
			"timestamps": {
				"from": "00:01:50,000",
				"to": "00:01:54,000"
			},
			"offsets": {
				"from": 110000,
				"to": 114000
			},
			"text": " one of our stories of trying to build solutions using snarks"
		},
		{
			"timestamps": {
				"from": "00:01:54,000",
				"to": "00:01:58,000"
			},
			"offsets": {
				"from": 114000,
				"to": 118000
			},
			"text": " and then actually running them on Ethereum mainnet."
		},
		{
			"timestamps": {
				"from": "00:01:58,000",
				"to": "00:02:02,000"
			},
			"offsets": {
				"from": 118000,
				"to": 122000
			},
			"text": " So, first, I think everybody here has at least heard of a snark."
		},
		{
			"timestamps": {
				"from": "00:02:02,000",
				"to": "00:02:07,000"
			},
			"offsets": {
				"from": 122000,
				"to": 127000
			},
			"text": " So, it's just a quick recap of the main character of our story."
		},
		{
			"timestamps": {
				"from": "00:02:07,000",
				"to": "00:02:10,000"
			},
			"offsets": {
				"from": 127000,
				"to": 130000
			},
			"text": " This is the expanded acronym of snarks,"
		},
		{
			"timestamps": {
				"from": "00:02:10,000",
				"to": "00:02:13,000"
			},
			"offsets": {
				"from": 130000,
				"to": 133000
			},
			"text": " a non-interactive argument of knowledge."
		},
		{
			"timestamps": {
				"from": "00:02:13,000",
				"to": "00:02:17,000"
			},
			"offsets": {
				"from": 133000,
				"to": 137000
			},
			"text": " In particular, what we care about is the sickness property of these snarks,"
		},
		{
			"timestamps": {
				"from": "00:02:17,000",
				"to": "00:02:21,000"
			},
			"offsets": {
				"from": 137000,
				"to": 141000
			},
			"text": " so it's kind of like that computation compressing the scalability solution"
		},
		{
			"timestamps": {
				"from": "00:02:21,000",
				"to": "00:02:24,000"
			},
			"offsets": {
				"from": 141000,
				"to": 144000
			},
			"text": " for Ethereum, those properties."
		},
		{
			"timestamps": {
				"from": "00:02:24,000",
				"to": "00:02:31,000"
			},
			"offsets": {
				"from": 144000,
				"to": 151000
			},
			"text": " One notable omission from our snark here is we don't have the ZK piece,"
		},
		{
			"timestamps": {
				"from": "00:02:31,000",
				"to": "00:02:35,000"
			},
			"offsets": {
				"from": 151000,
				"to": 155000
			},
			"text": " and so in our solutions, we don't necessarily care too much about the ZK,"
		},
		{
			"timestamps": {
				"from": "00:02:35,000",
				"to": "00:02:39,000"
			},
			"offsets": {
				"from": 155000,
				"to": 159000
			},
			"text": " the privacy piece, which is really this scalability piece that we're after."
		},
		{
			"timestamps": {
				"from": "00:02:39,000",
				"to": "00:02:43,000"
			},
			"offsets": {
				"from": 159000,
				"to": 163000
			},
			"text": " And then also, as I'm laying out the acronym snark,"
		},
		{
			"timestamps": {
				"from": "00:02:43,000",
				"to": "00:02:47,000"
			},
			"offsets": {
				"from": 163000,
				"to": 167000
			},
			"text": " I noticed something that one of my coworkers, 10-year-old daughters noticed,"
		},
		{
			"timestamps": {
				"from": "00:02:47,000",
				"to": "00:02:51,000"
			},
			"offsets": {
				"from": 167000,
				"to": 171000
			},
			"text": " and she said it shouldn't be called a snack,"
		},
		{
			"timestamps": {
				"from": "00:02:51,000",
				"to": "00:02:55,000"
			},
			"offsets": {
				"from": 171000,
				"to": 175000
			},
			"text": " and she's not wrong."
		},
		{
			"timestamps": {
				"from": "00:02:55,000",
				"to": "00:02:57,000"
			},
			"offsets": {
				"from": 175000,
				"to": 177000
			},
			"text": " All right, so our story."
		},
		{
			"timestamps": {
				"from": "00:02:57,000",
				"to": "00:03:01,000"
			},
			"offsets": {
				"from": 177000,
				"to": 181000
			},
			"text": " Every story has a challenge, a reason for it to exist,"
		},
		{
			"timestamps": {
				"from": "00:03:01,000",
				"to": "00:03:05,000"
			},
			"offsets": {
				"from": 181000,
				"to": 185000
			},
			"text": " and this is our challenge."
		},
		{
			"timestamps": {
				"from": "00:03:05,000",
				"to": "00:03:09,000"
			},
			"offsets": {
				"from": 185000,
				"to": 189000
			},
			"text": " You can't really see the bottom line there, but that's all right."
		},
		{
			"timestamps": {
				"from": "00:03:09,000",
				"to": "00:03:12,000"
			},
			"offsets": {
				"from": 189000,
				"to": 192000
			},
			"text": " So basically what we're trying to do is we are trying to use a snark"
		},
		{
			"timestamps": {
				"from": "00:03:12,000",
				"to": "00:03:18,000"
			},
			"offsets": {
				"from": 192000,
				"to": 198000
			},
			"text": " to resolve like 1 million independent payment channels within the graph protocol."
		},
		{
			"timestamps": {
				"from": "00:03:18,000",
				"to": "00:03:22,000"
			},
			"offsets": {
				"from": 198000,
				"to": 202000
			},
			"text": " So the graph protocol, the way that the insurance indexers get paid,"
		},
		{
			"timestamps": {
				"from": "00:03:22,000",
				"to": "00:03:26,000"
			},
			"offsets": {
				"from": 202000,
				"to": 206000
			},
			"text": " is they have an entity called the gateway, and every time the indexer"
		},
		{
			"timestamps": {
				"from": "00:03:26,000",
				"to": "00:03:31,000"
			},
			"offsets": {
				"from": 206000,
				"to": 211000
			},
			"text": " provides a result from a query, they get paid some amount,"
		},
		{
			"timestamps": {
				"from": "00:03:31,000",
				"to": "00:03:36,000"
			},
			"offsets": {
				"from": 211000,
				"to": 216000
			},
			"text": " and so in the gateway issues them a receipt that's been signed by the gateway,"
		},
		{
			"timestamps": {
				"from": "00:03:36,000",
				"to": "00:03:41,000"
			},
			"offsets": {
				"from": 216000,
				"to": 221000
			},
			"text": " and then it says what's the value of your transaction, right?"
		},
		{
			"timestamps": {
				"from": "00:03:41,000",
				"to": "00:03:45,000"
			},
			"offsets": {
				"from": 221000,
				"to": 225000
			},
			"text": " So the nice thing about the payment channel that the graph uses"
		},
		{
			"timestamps": {
				"from": "00:03:45,000",
				"to": "00:03:51,000"
			},
			"offsets": {
				"from": 225000,
				"to": 231000
			},
			"text": " is that you can basically instantiate up to a million independent kind of payment channels,"
		},
		{
			"timestamps": {
				"from": "00:03:51,000",
				"to": "00:03:55,000"
			},
			"offsets": {
				"from": 231000,
				"to": 235000
			},
			"text": " right, and these are all asynchronous, so the gateway can just be firing away receipts"
		},
		{
			"timestamps": {
				"from": "00:03:55,000",
				"to": "00:04:00,000"
			},
			"offsets": {
				"from": 235000,
				"to": 240000
			},
			"text": " as the indexer is serving queries, and so the indexer ends up with a bundle of,"
		},
		{
			"timestamps": {
				"from": "00:04:00,000",
				"to": "00:04:06,000"
			},
			"offsets": {
				"from": 240000,
				"to": 246000
			},
			"text": " say, a million different receipts, and their total amount that their owed"
		},
		{
			"timestamps": {
				"from": "00:04:06,000",
				"to": "00:04:11,000"
			},
			"offsets": {
				"from": 246000,
				"to": 251000
			},
			"text": " is kind of the sum of the total value over all of those receipts,"
		},
		{
			"timestamps": {
				"from": "00:04:11,000",
				"to": "00:04:14,000"
			},
			"offsets": {
				"from": 251000,
				"to": 254000
			},
			"text": " and so for the indexer to be able to prove that their owed,"
		},
		{
			"timestamps": {
				"from": "00:04:14,000",
				"to": "00:04:20,000"
			},
			"offsets": {
				"from": 254000,
				"to": 260000
			},
			"text": " the total amount that their owed, they need to somehow prove that all 1 million"
		},
		{
			"timestamps": {
				"from": "00:04:20,000",
				"to": "00:04:26,000"
			},
			"offsets": {
				"from": 260000,
				"to": 266000
			},
			"text": " of these receipts have valid signatures, that none of these receipts have been repeated,"
		},
		{
			"timestamps": {
				"from": "00:04:26,000",
				"to": "00:04:31,000"
			},
			"offsets": {
				"from": 266000,
				"to": 271000
			},
			"text": " and that the total value adds up to the total value that they claim that they're owned."
		},
		{
			"timestamps": {
				"from": "00:04:31,000",
				"to": "00:04:34,000"
			},
			"offsets": {
				"from": 271000,
				"to": 274000
			},
			"text": " And so one way they could do this right is they just take that bundle of a million receipts,"
		},
		{
			"timestamps": {
				"from": "00:04:34,000",
				"to": "00:04:38,000"
			},
			"offsets": {
				"from": 274000,
				"to": 278000
			},
			"text": " throw that on chain, and then run some, you know,"
		},
		{
			"timestamps": {
				"from": "00:04:38,000",
				"to": "00:04:43,000"
			},
			"offsets": {
				"from": 278000,
				"to": 283000
			},
			"text": " BL signature verification on all 1 million receipts, but, you know, that's a little costly,"
		},
		{
			"timestamps": {
				"from": "00:04:43,000",
				"to": "00:04:48,000"
			},
			"offsets": {
				"from": 283000,
				"to": 288000
			},
			"text": " so we want a better solution, and so the solution seems like really well suited for a snark, right?"
		},
		{
			"timestamps": {
				"from": "00:04:48,000",
				"to": "00:04:53,000"
			},
			"offsets": {
				"from": 288000,
				"to": 293000
			},
			"text": " Basically, we want to take this computation of, you know, a million different signature"
		},
		{
			"timestamps": {
				"from": "00:04:53,000",
				"to": "00:04:58,000"
			},
			"offsets": {
				"from": 293000,
				"to": 298000
			},
			"text": " verifications, throw it into a snark that can say, yes, all 1 million of these are valid,"
		},
		{
			"timestamps": {
				"from": "00:04:58,000",
				"to": "00:05:02,000"
			},
			"offsets": {
				"from": 298000,
				"to": 302000
			},
			"text": " total value adds up to the claim total value, all IDs are unique,"
		},
		{
			"timestamps": {
				"from": "00:05:02,000",
				"to": "00:05:08,000"
			},
			"offsets": {
				"from": 302000,
				"to": 308000
			},
			"text": " and then you get out just one nice little succinct proof with some claimed total value amount."
		},
		{
			"timestamps": {
				"from": "00:05:08,000",
				"to": "00:05:14,000"
			},
			"offsets": {
				"from": 308000,
				"to": 314000
			},
			"text": " That goes onto chain, and you run your snark verifier algorithm on chain,"
		},
		{
			"timestamps": {
				"from": "00:05:14,000",
				"to": "00:05:17,000"
			},
			"offsets": {
				"from": 314000,
				"to": 317000
			},
			"text": " and the indexer gets paid."
		},
		{
			"timestamps": {
				"from": "00:05:17,000",
				"to": "00:05:22,000"
			},
			"offsets": {
				"from": 317000,
				"to": 322000
			},
			"text": " And so let's look a little closer at this problem and why it's interesting,"
		},
		{
			"timestamps": {
				"from": "00:05:22,000",
				"to": "00:05:26,000"
			},
			"offsets": {
				"from": 322000,
				"to": 326000
			},
			"text": " this table here that we're generating, right, this bundle of receipts,"
		},
		{
			"timestamps": {
				"from": "00:05:26,000",
				"to": "00:05:29,000"
			},
			"offsets": {
				"from": 326000,
				"to": 329000
			},
			"text": " we've got a million different receipts, and so whenever we talk about snarks,"
		},
		{
			"timestamps": {
				"from": "00:05:29,000",
				"to": "00:05:33,000"
			},
			"offsets": {
				"from": 329000,
				"to": 333000
			},
			"text": " there's always this talk of like, okay, what circuits are used to verify your computation"
		},
		{
			"timestamps": {
				"from": "00:05:33,000",
				"to": "00:05:37,000"
			},
			"offsets": {
				"from": 333000,
				"to": 337000
			},
			"text": " and all that type of stuff? So basically our circuit needs to take in"
		},
		{
			"timestamps": {
				"from": "00:05:37,000",
				"to": "00:05:42,000"
			},
			"offsets": {
				"from": 337000,
				"to": 342000
			},
			"text": " actively needs to prove 1 million different signature verifications,"
		},
		{
			"timestamps": {
				"from": "00:05:42,000",
				"to": "00:05:45,000"
			},
			"offsets": {
				"from": 342000,
				"to": 345000
			},
			"text": " so initially we're thinking about using BLS signatures,"
		},
		{
			"timestamps": {
				"from": "00:05:45,000",
				"to": "00:05:51,000"
			},
			"offsets": {
				"from": 345000,
				"to": 351000
			},
			"text": " you can maybe see that a BLS signature can be proved with the circuit of size, say, 2 to the 8."
		},
		{
			"timestamps": {
				"from": "00:05:51,000",
				"to": "00:05:57,000"
			},
			"offsets": {
				"from": 351000,
				"to": 357000
			},
			"text": " If you wanted to prove all 1 million of those transactions with this size to the 8 circuit,"
		},
		{
			"timestamps": {
				"from": "00:05:57,000",
				"to": "00:06:00,000"
			},
			"offsets": {
				"from": 357000,
				"to": 360000
			},
			"text": " you could just take the 2 to the 8 circuit, copy and paste it,"
		},
		{
			"timestamps": {
				"from": "00:06:00,000",
				"to": "00:06:05,000"
			},
			"offsets": {
				"from": 360000,
				"to": 365000
			},
			"text": " and then you have some huge size 2 to the 28 circuit that you're going to be using in your snark"
		},
		{
			"timestamps": {
				"from": "00:06:05,000",
				"to": "00:06:08,000"
			},
			"offsets": {
				"from": 365000,
				"to": 368000
			},
			"text": " to verify and to prove and verify."
		},
		{
			"timestamps": {
				"from": "00:06:08,000",
				"to": "00:06:14,000"
			},
			"offsets": {
				"from": 368000,
				"to": 374000
			},
			"text": " And so what's interesting about that is 2 to the 28 is about the biggest circuit size you'll see, right?"
		},
		{
			"timestamps": {
				"from": "00:06:14,000",
				"to": "00:06:17,000"
			},
			"offsets": {
				"from": 374000,
				"to": 377000
			},
			"text": " So in all the literature and all this stuff, people run their asymptotics"
		},
		{
			"timestamps": {
				"from": "00:06:17,000",
				"to": "00:06:21,000"
			},
			"offsets": {
				"from": 377000,
				"to": 381000
			},
			"text": " and they go up to size 2 to the 28, and we haven't really seen much bigger than that."
		},
		{
			"timestamps": {
				"from": "00:06:21,000",
				"to": "00:06:26,000"
			},
			"offsets": {
				"from": 381000,
				"to": 386000
			},
			"text": " And so already we're talking about trying to prove statements that are at the edge of what people have used,"
		},
		{
			"timestamps": {
				"from": "00:06:26,000",
				"to": "00:06:33,000"
			},
			"offsets": {
				"from": 386000,
				"to": 393000
			},
			"text": " and another really interesting thing about this primitive is we're trying to use a snark as a black box,"
		},
		{
			"timestamps": {
				"from": "00:06:33,000",
				"to": "00:06:36,000"
			},
			"offsets": {
				"from": 393000,
				"to": 396000
			},
			"text": " so really we're just trying to get incorporated into this payment channel protocol,"
		},
		{
			"timestamps": {
				"from": "00:06:36,000",
				"to": "00:06:42,000"
			},
			"offsets": {
				"from": 396000,
				"to": 402000
			},
			"text": " and we don't really want to have the snark impose any extra requirements on the protocol itself, right?"
		},
		{
			"timestamps": {
				"from": "00:06:42,000",
				"to": "00:06:45,000"
			},
			"offsets": {
				"from": 402000,
				"to": 405000
			},
			"text": " We just want the snark to be this black box, we plug in a scalar table,"
		},
		{
			"timestamps": {
				"from": "00:06:45,000",
				"to": "00:06:48,000"
			},
			"offsets": {
				"from": 405000,
				"to": 408000
			},
			"text": " we get out of proof, that proof goes on chain, you can verify it,"
		},
		{
			"timestamps": {
				"from": "00:06:48,000",
				"to": "00:06:54,000"
			},
			"offsets": {
				"from": 408000,
				"to": 414000
			},
			"text": " and you don't really impact the security of the system in any way based off of your snark."
		},
		{
			"timestamps": {
				"from": "00:06:54,000",
				"to": "00:06:58,000"
			},
			"offsets": {
				"from": 414000,
				"to": 418000
			},
			"text": " And then the final thing here, the business side of this,"
		},
		{
			"timestamps": {
				"from": "00:06:58,000",
				"to": "00:07:04,000"
			},
			"offsets": {
				"from": 418000,
				"to": 424000
			},
			"text": " oh yeah, can you make this whole process of proving and verifying cost less than $30?"
		},
		{
			"timestamps": {
				"from": "00:07:04,000",
				"to": "00:07:09,000"
			},
			"offsets": {
				"from": 424000,
				"to": 429000
			},
			"text": " Otherwise it's not very useful to the indexer, so thanks."
		},
		{
			"timestamps": {
				"from": "00:07:09,000",
				"to": "00:07:11,000"
			},
			"offsets": {
				"from": 429000,
				"to": 431000
			},
			"text": " Yo."
		},
		{
			"timestamps": {
				"from": "00:07:11,000",
				"to": "00:07:17,000"
			},
			"offsets": {
				"from": 431000,
				"to": 437000
			},
			"text": " Alright, so now we're going, we got our challenge, we're trying to prove this massive table of data,"
		},
		{
			"timestamps": {
				"from": "00:07:17,000",
				"to": "00:07:21,000"
			},
			"offsets": {
				"from": 437000,
				"to": 441000
			},
			"text": " and prove this massive table of signature verifications."
		},
		{
			"timestamps": {
				"from": "00:07:21,000",
				"to": "00:07:25,000"
			},
			"offsets": {
				"from": 441000,
				"to": 445000
			},
			"text": " How do we know whenever we're done, right? How do we know that we've succeeded?"
		},
		{
			"timestamps": {
				"from": "00:07:25,000",
				"to": "00:07:28,000"
			},
			"offsets": {
				"from": 445000,
				"to": 448000
			},
			"text": " There's a bunch of different metrics to quantify snark performance,"
		},
		{
			"timestamps": {
				"from": "00:07:28,000",
				"to": "00:07:33,000"
			},
			"offsets": {
				"from": 448000,
				"to": 453000
			},
			"text": " we use proof of time, proof of memory, proof size, and verify or compute."
		},
		{
			"timestamps": {
				"from": "00:07:33,000",
				"to": "00:07:38,000"
			},
			"offsets": {
				"from": 453000,
				"to": 458000
			},
			"text": " So proof of time is basically just, it's about the time that the proofer spends generating their proof, right?"
		},
		{
			"timestamps": {
				"from": "00:07:38,000",
				"to": "00:07:41,000"
			},
			"offsets": {
				"from": 458000,
				"to": 461000
			},
			"text": " So in this case it's the indexer, the indexer has their big table,"
		},
		{
			"timestamps": {
				"from": "00:07:41,000",
				"to": "00:07:46,000"
			},
			"offsets": {
				"from": 461000,
				"to": 466000
			},
			"text": " they're going to run this proving algorithm, it's going to take them some amount of time to generate that proof."
		},
		{
			"timestamps": {
				"from": "00:07:46,000",
				"to": "00:07:51,000"
			},
			"offsets": {
				"from": 466000,
				"to": 471000
			},
			"text": " So proof of memory, this is like an actual physical requirements of the machine that they're using to generate this proof, right?"
		},
		{
			"timestamps": {
				"from": "00:07:51,000",
				"to": "00:07:58,000"
			},
			"offsets": {
				"from": 471000,
				"to": 478000
			},
			"text": " So they've got, if they got a laptop with 16 gigs of memory, you're not going to, the algorithm requires more than 16 gigs of memory,"
		},
		{
			"timestamps": {
				"from": "00:07:58,000",
				"to": "00:08:01,000"
			},
			"offsets": {
				"from": 478000,
				"to": 481000
			},
			"text": " you're going to run into issues, you're not going to be able to generate a proof."
		},
		{
			"timestamps": {
				"from": "00:08:01,000",
				"to": "00:08:06,000"
			},
			"offsets": {
				"from": 481000,
				"to": 486000
			},
			"text": " Proof size, this is the size of that proof that gets spit out of the snark, this is what gets sent on chain,"
		},
		{
			"timestamps": {
				"from": "00:08:06,000",
				"to": "00:08:10,000"
			},
			"offsets": {
				"from": 486000,
				"to": 490000
			},
			"text": " so this is obviously important, right, the bigger your proof is, the more expensive it is to store it."
		},
		{
			"timestamps": {
				"from": "00:08:10,000",
				"to": "00:08:16,000"
			},
			"offsets": {
				"from": 490000,
				"to": 496000
			},
			"text": " And then verify or compute, these are the computations that are run on chain in the verify algorithm."
		},
		{
			"timestamps": {
				"from": "00:08:16,000",
				"to": "00:08:20,000"
			},
			"offsets": {
				"from": 496000,
				"to": 500000
			},
			"text": " And for the purpose of this talk, whenever we talk about the verify compute,"
		},
		{
			"timestamps": {
				"from": "00:08:20,000",
				"to": "00:08:25,000"
			},
			"offsets": {
				"from": 500000,
				"to": 505000
			},
			"text": " we're really going to just highlight the most expensive operations that the verifier is going to run."
		},
		{
			"timestamps": {
				"from": "00:08:25,000",
				"to": "00:08:32,000"
			},
			"offsets": {
				"from": 505000,
				"to": 512000
			},
			"text": " And so this gives us kind of like a quick way to filter out techniques and estimate gas causes and all that."
		},
		{
			"timestamps": {
				"from": "00:08:32,000",
				"to": "00:08:39,000"
			},
			"offsets": {
				"from": 512000,
				"to": 519000
			},
			"text": " Just another thing on these figures, right, we'll see them repeatedly, this x-axis, basically this is showing our statement size"
		},
		{
			"timestamps": {
				"from": "00:08:39,000",
				"to": "00:08:44,000"
			},
			"offsets": {
				"from": 519000,
				"to": 524000
			},
			"text": " as it's growing, right, so we said we want to prove this big table of signature verifications."
		},
		{
			"timestamps": {
				"from": "00:08:44,000",
				"to": "00:08:54,000"
			},
			"offsets": {
				"from": 524000,
				"to": 534000
			},
			"text": " The goal is to get to this kind of size two to the 28 instance, and then by seeing, you know, how this, how these metrics trend,"
		},
		{
			"timestamps": {
				"from": "00:08:54,000",
				"to": "00:09:01,000"
			},
			"offsets": {
				"from": 534000,
				"to": 541000
			},
			"text": " we can kind of get an idea for like engineering solutions, right, and we get an idea how our problems are growing and stuff like that."
		},
		{
			"timestamps": {
				"from": "00:09:01,000",
				"to": "00:09:04,000"
			},
			"offsets": {
				"from": 541000,
				"to": 544000
			},
			"text": " So, those are our plots."
		},
		{
			"timestamps": {
				"from": "00:09:04,000",
				"to": "00:09:09,000"
			},
			"offsets": {
				"from": 544000,
				"to": 549000
			},
			"text": " And now we start our story, and I like maps, and I like stories with maps."
		},
		{
			"timestamps": {
				"from": "00:09:09,000",
				"to": "00:09:17,000"
			},
			"offsets": {
				"from": 549000,
				"to": 557000
			},
			"text": " And so we're going to have a map, but a quick caveat about maps is this is a map of the world in 450 BC."
		},
		{
			"timestamps": {
				"from": "00:09:17,000",
				"to": "00:09:23,000"
			},
			"offsets": {
				"from": 557000,
				"to": 563000
			},
			"text": " It's accurate, but we can tell it's not the full truth, right, there's a whole lot to be discovered still."
		},
		{
			"timestamps": {
				"from": "00:09:23,000",
				"to": "00:09:25,000"
			},
			"offsets": {
				"from": 563000,
				"to": 565000
			},
			"text": " So, here's our map."
		},
		{
			"timestamps": {
				"from": "00:09:25,000",
				"to": "00:09:32,000"
			},
			"offsets": {
				"from": 565000,
				"to": 572000
			},
			"text": " This is cryptography land as we saw it at the start of this program, and especially in particular when we're looking at snarks."
		},
		{
			"timestamps": {
				"from": "00:09:32,000",
				"to": "00:09:35,000"
			},
			"offsets": {
				"from": 572000,
				"to": 575000
			},
			"text": " So, we've got kind of two major continents of snarks."
		},
		{
			"timestamps": {
				"from": "00:09:35,000",
				"to": "00:09:39,000"
			},
			"offsets": {
				"from": 575000,
				"to": 579000
			},
			"text": " We've got transparent snarks, and we've got these non-transparent snarks."
		},
		{
			"timestamps": {
				"from": "00:09:39,000",
				"to": "00:09:43,000"
			},
			"offsets": {
				"from": 579000,
				"to": 583000
			},
			"text": " And so, non-transparent snarks, these are snarks that require some sort of trusted setup."
		},
		{
			"timestamps": {
				"from": "00:09:43,000",
				"to": "00:09:49,000"
			},
			"offsets": {
				"from": 583000,
				"to": 589000
			},
			"text": " So, we saw yesterday when we were talking about dang charting, and we're going to have this KZG trusted setup ceremony."
		},
		{
			"timestamps": {
				"from": "00:09:49,000",
				"to": "00:09:53,000"
			},
			"offsets": {
				"from": 589000,
				"to": 593000
			},
			"text": " That ceremony is what is required for these non-transparent snarks."
		},
		{
			"timestamps": {
				"from": "00:09:53,000",
				"to": "00:09:58,000"
			},
			"offsets": {
				"from": 593000,
				"to": 598000
			},
			"text": " Transparent snarks, the idea is they don't require this kind of trusted setup ceremony."
		},
		{
			"timestamps": {
				"from": "00:09:58,000",
				"to": "00:10:01,000"
			},
			"offsets": {
				"from": 598000,
				"to": 601000
			},
			"text": " You can kind of run them out of the box."
		},
		{
			"timestamps": {
				"from": "00:10:01,000",
				"to": "00:10:03,000"
			},
			"offsets": {
				"from": 601000,
				"to": 603000
			},
			"text": " So, that's our map."
		},
		{
			"timestamps": {
				"from": "00:10:03,000",
				"to": "00:10:07,000"
			},
			"offsets": {
				"from": 603000,
				"to": 607000
			},
			"text": " Now, we say, where do we begin, right, how do we start this story?"
		},
		{
			"timestamps": {
				"from": "00:10:07,000",
				"to": "00:10:13,000"
			},
			"offsets": {
				"from": 607000,
				"to": 613000
			},
			"text": " And really, when we started out, we saw, okay, one of these unique properties of the problem, it's a black box."
		},
		{
			"timestamps": {
				"from": "00:10:13,000",
				"to": "00:10:19,000"
			},
			"offsets": {
				"from": 613000,
				"to": 619000
			},
			"text": " Like we said, we don't want the snark to impose any security requirements on top of the system that we're using."
		},
		{
			"timestamps": {
				"from": "00:10:19,000",
				"to": "00:10:30,000"
			},
			"offsets": {
				"from": 619000,
				"to": 630000
			},
			"text": " And so, when we think about this trusted setup, we can debate how, like, the practical implications of this trusted setup."
		},
		{
			"timestamps": {
				"from": "00:10:30,000",
				"to": "00:10:36,000"
			},
			"offsets": {
				"from": 630000,
				"to": 636000
			},
			"text": " Like, if you only have two people running the trusted setup ceremony, you have to trust that both of them are honest."
		},
		{
			"timestamps": {
				"from": "00:10:36,000",
				"to": "00:10:41,000"
			},
			"offsets": {
				"from": 636000,
				"to": 641000
			},
			"text": " As you increase the number of participants, that level of trust might change."
		},
		{
			"timestamps": {
				"from": "00:10:41,000",
				"to": "00:10:44,000"
			},
			"offsets": {
				"from": 641000,
				"to": 644000
			},
			"text": " But the point is, you're still making an argument."
		},
		{
			"timestamps": {
				"from": "00:10:44,000",
				"to": "00:10:48,000"
			},
			"offsets": {
				"from": 644000,
				"to": 648000
			},
			"text": " There's still some other additional argument that goes on top of the math of your proving system."
		},
		{
			"timestamps": {
				"from": "00:10:48,000",
				"to": "00:10:52,000"
			},
			"offsets": {
				"from": 648000,
				"to": 652000
			},
			"text": " And so, initially, we said we want this thing to be as black box as possible."
		},
		{
			"timestamps": {
				"from": "00:10:52,000",
				"to": "00:10:54,000"
			},
			"offsets": {
				"from": 652000,
				"to": 654000
			},
			"text": " We don't want to have to deal with those extra arguments."
		},
		{
			"timestamps": {
				"from": "00:10:54,000",
				"to": "00:10:58,000"
			},
			"offsets": {
				"from": 654000,
				"to": 658000
			},
			"text": " So, we want to start with the transparent snark."
		},
		{
			"timestamps": {
				"from": "00:10:58,000",
				"to": "00:11:04,000"
			},
			"offsets": {
				"from": 658000,
				"to": 664000
			},
			"text": " All right, so now knowing that we're going to be using a transparent snark, where do we go from here?"
		},
		{
			"timestamps": {
				"from": "00:11:04,000",
				"to": "00:11:12,000"
			},
			"offsets": {
				"from": 664000,
				"to": 672000
			},
			"text": " And so, we start by looking at our problem statement, and we start trying to find, you know, what's the next best snark to use."
		},
		{
			"timestamps": {
				"from": "00:11:12,000",
				"to": "00:11:16,000"
			},
			"offsets": {
				"from": 672000,
				"to": 676000
			},
			"text": " The thing that's unique about this problem statement, right, is it's highly structured."
		},
		{
			"timestamps": {
				"from": "00:11:16,000",
				"to": "00:11:21,000"
			},
			"offsets": {
				"from": 676000,
				"to": 681000
			},
			"text": " So, basically, we're kind of proving the same function, you know, a million times."
		},
		{
			"timestamps": {
				"from": "00:11:21,000",
				"to": "00:11:31,000"
			},
			"offsets": {
				"from": 681000,
				"to": 691000
			},
			"text": " So, if we could basically, if we could kind of reuse these circuits, right, maybe we could significantly reduce costs,"
		},
		{
			"timestamps": {
				"from": "00:11:31,000",
				"to": "00:11:34,000"
			},
			"offsets": {
				"from": 691000,
				"to": 694000
			},
			"text": " either proof size, verification time, that type of thing."
		},
		{
			"timestamps": {
				"from": "00:11:34,000",
				"to": "00:11:44,000"
			},
			"offsets": {
				"from": 694000,
				"to": 704000
			},
			"text": " And so, in particular, what we're curious about is, we could come up with one circuit, this is some F circuit that can be used to prove all of these snark things for a single row."
		},
		{
			"timestamps": {
				"from": "00:11:44,000",
				"to": "00:11:49,000"
			},
			"offsets": {
				"from": 704000,
				"to": 709000
			},
			"text": " And so, then, if we could do that, then could we, you know, generate proofs for each individual row,"
		},
		{
			"timestamps": {
				"from": "00:11:49,000",
				"to": "00:11:51,000"
			},
			"offsets": {
				"from": 709000,
				"to": 711000
			},
			"text": " and then somehow, like, aggregate them all together."
		},
		{
			"timestamps": {
				"from": "00:11:51,000",
				"to": "00:12:02,000"
			},
			"offsets": {
				"from": 711000,
				"to": 722000
			},
			"text": " And then, we get some aggregate proof, and the hope is that an aggregate proof will cost only about the same to verify as verifying this single small proof."
		},
		{
			"timestamps": {
				"from": "00:12:02,000",
				"to": "00:12:05,000"
			},
			"offsets": {
				"from": 722000,
				"to": 725000
			},
			"text": " So, people have been looking in snarks."
		},
		{
			"timestamps": {
				"from": "00:12:05,000",
				"to": "00:12:07,000"
			},
			"offsets": {
				"from": 725000,
				"to": 727000
			},
			"text": " You can see where we're kind of going with this."
		},
		{
			"timestamps": {
				"from": "00:12:07,000",
				"to": "00:12:10,000"
			},
			"offsets": {
				"from": 727000,
				"to": 730000
			},
			"text": " We are going to recursive snark land."
		},
		{
			"timestamps": {
				"from": "00:12:10,000",
				"to": "00:12:13,000"
			},
			"offsets": {
				"from": 730000,
				"to": 733000
			},
			"text": " And so, in this space, there's a couple of primitives."
		},
		{
			"timestamps": {
				"from": "00:12:13,000",
				"to": "00:12:16,000"
			},
			"offsets": {
				"from": 733000,
				"to": 736000
			},
			"text": " Halo is one of the big ones we hear about."
		},
		{
			"timestamps": {
				"from": "00:12:16,000",
				"to": "00:12:19,000"
			},
			"offsets": {
				"from": 736000,
				"to": 739000
			},
			"text": " And there's talks on it this week."
		},
		{
			"timestamps": {
				"from": "00:12:19,000",
				"to": "00:12:26,000"
			},
			"offsets": {
				"from": 739000,
				"to": 746000
			},
			"text": " But at a very high level, recursive snarks, it's kind of like what I was saying, right?"
		},
		{
			"timestamps": {
				"from": "00:12:26,000",
				"to": "00:12:32,000"
			},
			"offsets": {
				"from": 746000,
				"to": 752000
			},
			"text": " We have the idea is we have a circuit, we want to repeat the computations on that circuit, and then kind of aggregate these proofs together."
		},
		{
			"timestamps": {
				"from": "00:12:32,000",
				"to": "00:12:41,000"
			},
			"offsets": {
				"from": 752000,
				"to": 761000
			},
			"text": " And the way that recursive snarks tend to get around this in practice is you take your original circuit, you can augment it with some snark verify circuit,"
		},
		{
			"timestamps": {
				"from": "00:12:41,000",
				"to": "00:12:44,000"
			},
			"offsets": {
				"from": 761000,
				"to": 764000
			},
			"text": " and it runs the verify algorithm of your proving system."
		},
		{
			"timestamps": {
				"from": "00:12:44,000",
				"to": "00:12:52,000"
			},
			"offsets": {
				"from": 764000,
				"to": 772000
			},
			"text": " And then you have some result that F prime circuit, and then this F prime circuit is kind of what you start chaining together to prove all of your rows,"
		},
		{
			"timestamps": {
				"from": "00:12:52,000",
				"to": "00:12:54,000"
			},
			"offsets": {
				"from": 772000,
				"to": 774000
			},
			"text": " in our case, prove the rows of the scalar table."
		},
		{
			"timestamps": {
				"from": "00:12:54,000",
				"to": "00:13:07,000"
			},
			"offsets": {
				"from": 774000,
				"to": 787000
			},
			"text": " And the really important thing here is the cost to verify, and like the cost and proof size, is really only tied to the cost for proving and verifying this one F prime circuit."
		},
		{
			"timestamps": {
				"from": "00:13:07,000",
				"to": "00:13:09,000"
			},
			"offsets": {
				"from": 787000,
				"to": 789000
			},
			"text": " So, that's really encouraging."
		},
		{
			"timestamps": {
				"from": "00:13:09,000",
				"to": "00:13:17,000"
			},
			"offsets": {
				"from": 789000,
				"to": 797000
			},
			"text": " Maybe we could significantly reduce our problem using this."
		},
		{
			"timestamps": {
				"from": "00:13:17,000",
				"to": "00:13:25,000"
			},
			"offsets": {
				"from": 797000,
				"to": 805000
			},
			"text": " We use a primitive called Nova, so it hasn't seen too much traction in this community that I've seen yet,"
		},
		{
			"timestamps": {
				"from": "00:13:25,000",
				"to": "00:13:29,000"
			},
			"offsets": {
				"from": 805000,
				"to": 809000
			},
			"text": " but it's a newer primitive, it was presented at crypto this year."
		},
		{
			"timestamps": {
				"from": "00:13:29,000",
				"to": "00:13:36,000"
			},
			"offsets": {
				"from": 809000,
				"to": 816000
			},
			"text": " What it really has going for it is it can do kind of what Halo does, but it has the smallest constant size verifier circuit."
		},
		{
			"timestamps": {
				"from": "00:13:36,000",
				"to": "00:13:39,000"
			},
			"offsets": {
				"from": 816000,
				"to": 819000
			},
			"text": " So we remember that F prime, you have that little verify circuit."
		},
		{
			"timestamps": {
				"from": "00:13:39,000",
				"to": "00:13:48,000"
			},
			"offsets": {
				"from": 819000,
				"to": 828000
			},
			"text": " Nova is the smallest that exists in the current literature, and it's constant size, so it doesn't depend on the size of your original F circuit."
		},
		{
			"timestamps": {
				"from": "00:13:48,000",
				"to": "00:13:59,000"
			},
			"offsets": {
				"from": 828000,
				"to": 839000
			},
			"text": " Just a note, in our case, this F prime circuit ends up being about size two to the 15, and so this is this constant proof size,"
		},
		{
			"timestamps": {
				"from": "00:13:59,000",
				"to": "00:14:04,000"
			},
			"offsets": {
				"from": 839000,
				"to": 844000
			},
			"text": " and the verifier work is tied directly to this kind of two to the 15."
		},
		{
			"timestamps": {
				"from": "00:14:04,000",
				"to": "00:14:10,000"
			},
			"offsets": {
				"from": 844000,
				"to": 850000
			},
			"text": " Another interesting thing about Nova is it uses another IOP called Spartan,"
		},
		{
			"timestamps": {
				"from": "00:14:10,000",
				"to": "00:14:18,000"
			},
			"offsets": {
				"from": 850000,
				"to": 858000
			},
			"text": " and what Spartan does, or its advantage, it's a very fast prover, and it might still be the fastest prover in the literature."
		},
		{
			"timestamps": {
				"from": "00:14:18,000",
				"to": "00:14:23,000"
			},
			"offsets": {
				"from": 858000,
				"to": 863000
			},
			"text": " It doesn't use any VA FFTs, and it also has a relatively efficient verifier."
		},
		{
			"timestamps": {
				"from": "00:14:23,000",
				"to": "00:14:28,000"
			},
			"offsets": {
				"from": 863000,
				"to": 868000
			},
			"text": " Some more notes about Nova, the actual open source implementation that they have,"
		},
		{
			"timestamps": {
				"from": "00:14:28,000",
				"to": "00:14:36,000"
			},
			"offsets": {
				"from": 868000,
				"to": 876000
			},
			"text": " and it's very instantiated with bulletproofs IPA, so this is kind of like the expensive IPA that people talk about in the literature,"
		},
		{
			"timestamps": {
				"from": "00:14:36,000",
				"to": "00:14:39,000"
			},
			"offsets": {
				"from": 876000,
				"to": 879000
			},
			"text": " the expensive polynomial commitment scheme."
		},
		{
			"timestamps": {
				"from": "00:14:39,000",
				"to": "00:14:47,000"
			},
			"offsets": {
				"from": 879000,
				"to": 887000
			},
			"text": " But that is, this bulletproofs is only used for a circuit of this size, so you end up with a bulletproofs instance on your polynomial commitment."
		},
		{
			"timestamps": {
				"from": "00:14:47,000",
				"to": "00:14:49,000"
			},
			"offsets": {
				"from": 887000,
				"to": 889000
			},
			"text": " It's tied to this size."
		},
		{
			"timestamps": {
				"from": "00:14:49,000",
				"to": "00:14:54,000"
			},
			"offsets": {
				"from": 889000,
				"to": 894000
			},
			"text": " And then just another note on their open source implementation, they're using these pasta curves, so similar to Halo."
		},
		{
			"timestamps": {
				"from": "00:14:54,000",
				"to": "00:15:03,000"
			},
			"offsets": {
				"from": 894000,
				"to": 903000
			},
			"text": " When you're generating these recursive proving systems, you have some kind of unique mathematical primitives that you've got to use,"
		},
		{
			"timestamps": {
				"from": "00:15:03,000",
				"to": "00:15:07,000"
			},
			"offsets": {
				"from": 903000,
				"to": 907000
			},
			"text": " and so in that particular it's called these cycles of elliptic curves,"
		},
		{
			"timestamps": {
				"from": "00:15:07,000",
				"to": "00:15:15,000"
			},
			"offsets": {
				"from": 907000,
				"to": 915000
			},
			"text": " and Nova uses the same thing that pasta does, and they actually work together on this, so nothing too surprising there."
		},
		{
			"timestamps": {
				"from": "00:15:15,000",
				"to": "00:15:20,000"
			},
			"offsets": {
				"from": 915000,
				"to": 920000
			},
			"text": " What gets surprising now is when are we actually looking at our costs?"
		},
		{
			"timestamps": {
				"from": "00:15:20,000",
				"to": "00:15:28,000"
			},
			"offsets": {
				"from": 920000,
				"to": 928000
			},
			"text": " The first thing that we notice is these constant size here, so the proof size is constant, this verifier is compute is constant."
		},
		{
			"timestamps": {
				"from": "00:15:28,000",
				"to": "00:15:34,000"
			},
			"offsets": {
				"from": 928000,
				"to": 934000
			},
			"text": " So basically what we're saying is as we increase on our x-axis here, we're basically proving more and more rows in our scalar table,"
		},
		{
			"timestamps": {
				"from": "00:15:34,000",
				"to": "00:15:42,000"
			},
			"offsets": {
				"from": 934000,
				"to": 942000
			},
			"text": " and this proof size and this verifier compute stay constant, because again the proof and the proof size and the verifier compute are tied only to that f prime circuit."
		},
		{
			"timestamps": {
				"from": "00:15:42,000",
				"to": "00:15:49,000"
			},
			"offsets": {
				"from": 942000,
				"to": 949000
			},
			"text": " So we get this nice kind of constant proof size, verify compute, it doesn't depend on the number of rows that we're trying to prove."
		},
		{
			"timestamps": {
				"from": "00:15:49,000",
				"to": "00:15:57,000"
			},
			"offsets": {
				"from": 949000,
				"to": 957000
			},
			"text": " The prover time here, this is pretty much linear in the instance size that we're trying to prove, so linear in the number of rows that we're trying to prove."
		},
		{
			"timestamps": {
				"from": "00:15:57,000",
				"to": "00:16:00,000"
			},
			"offsets": {
				"from": 957000,
				"to": 960000
			},
			"text": " Because basically the prover has to do the work, right?"
		},
		{
			"timestamps": {
				"from": "00:16:00,000",
				"to": "00:16:11,000"
			},
			"offsets": {
				"from": 960000,
				"to": 971000
			},
			"text": " So in this particular instantiation, the prover is just kind of going row by row, kind of proving and accumulating, so you kind of just see this linear growth here."
		},
		{
			"timestamps": {
				"from": "00:16:11,000",
				"to": "00:16:26,000"
			},
			"offsets": {
				"from": 971000,
				"to": 986000
			},
			"text": " And so I mean, based off the implementation that we have available, we would estimate 51 hours to prove using NOVA for an instance as big as we want to get."
		},
		{
			"timestamps": {
				"from": "00:16:26,000",
				"to": "00:16:33,000"
			},
			"offsets": {
				"from": 986000,
				"to": 993000
			},
			"text": " That may or may not be a fundamental limiter, but really what we see, the big limiter is this verify compute."
		},
		{
			"timestamps": {
				"from": "00:16:33,000",
				"to": "00:16:38,000"
			},
			"offsets": {
				"from": 993000,
				"to": 998000
			},
			"text": " So even though verify compute is constant, it still is a very expensive operation that needs to run."
		},
		{
			"timestamps": {
				"from": "00:16:38,000",
				"to": "00:16:42,000"
			},
			"offsets": {
				"from": 998000,
				"to": 1002000
			},
			"text": " And so in particular, it's part of this bulletproofs polynomial commitment scheme."
		},
		{
			"timestamps": {
				"from": "00:16:42,000",
				"to": "00:16:53,000"
			},
			"offsets": {
				"from": 1002000,
				"to": 1013000
			},
			"text": " You have to run this elliptic curve multi exponentiation and it's, you know, size 2 to the 15, so 32,000, basically elliptic curve multiplications."
		},
		{
			"timestamps": {
				"from": "00:16:53,000",
				"to": "00:17:03,000"
			},
			"offsets": {
				"from": 1013000,
				"to": 1023000
			},
			"text": " And so the problem really is, NOVA is in that work with pasta curves, Ethereum only has precompile support for one curve, all to be in 128."
		},
		{
			"timestamps": {
				"from": "00:17:03,000",
				"to": "00:17:07,000"
			},
			"offsets": {
				"from": 1023000,
				"to": 1027000
			},
			"text": " And so this is kind of a famously known problem at this point."
		},
		{
			"timestamps": {
				"from": "00:17:07,000",
				"to": "00:17:18,000"
			},
			"offsets": {
				"from": 1027000,
				"to": 1038000
			},
			"text": " So if you wanted to run this verify algorithm, you'd have to implement smart contracts for pasta curves, so that itself is a cost that we would have to absorb."
		},
		{
			"timestamps": {
				"from": "00:17:18,000",
				"to": "00:17:26,000"
			},
			"offsets": {
				"from": 1038000,
				"to": 1046000
			},
			"text": " And then if we did, we would see, you know, based off of some people who have done a similar work, a scalar moment would still cost about 350,000 gas."
		},
		{
			"timestamps": {
				"from": "00:17:26,000",
				"to": "00:17:42,000"
			},
			"offsets": {
				"from": 1046000,
				"to": 1062000
			},
			"text": " And so if we could use, you know, some algorithms for speeding up this multi exponentiation, we could get these total costs down to, you know, 764 million gas, or, you know, $76,000 off of some estimate of gas to dollar ratio."
		},
		{
			"timestamps": {
				"from": "00:17:42,000",
				"to": "00:17:46,000"
			},
			"offsets": {
				"from": 1062000,
				"to": 1066000
			},
			"text": " So clearly, this isn't the solution that we're looking for."
		},
		{
			"timestamps": {
				"from": "00:17:46,000",
				"to": "00:17:52,000"
			},
			"offsets": {
				"from": 1066000,
				"to": 1072000
			},
			"text": " Maybe there's some engineering things we could do, we could take advantage of all the N128, it also has a cycle."
		},
		{
			"timestamps": {
				"from": "00:17:52,000",
				"to": "00:17:57,000"
			},
			"offsets": {
				"from": 1072000,
				"to": 1077000
			},
			"text": " But for now, we'll table this and we'll go elsewhere."
		},
		{
			"timestamps": {
				"from": "00:17:57,000",
				"to": "00:18:00,000"
			},
			"offsets": {
				"from": 1077000,
				"to": 1080000
			},
			"text": " So where do we go from here?"
		},
		{
			"timestamps": {
				"from": "00:18:00,000",
				"to": "00:18:08,000"
			},
			"offsets": {
				"from": 1080000,
				"to": 1088000
			},
			"text": " Again, we want a transparent snark, and we would really like to use primitives that can take advantage of, you know, things that are supported by Ethereum."
		},
		{
			"timestamps": {
				"from": "00:18:08,000",
				"to": "00:18:13,000"
			},
			"offsets": {
				"from": 1088000,
				"to": 1093000
			},
			"text": " So we look for primitives that use all BN 128, all BN 128 is a pairing friendly curve."
		},
		{
			"timestamps": {
				"from": "00:18:13,000",
				"to": "00:18:17,000"
			},
			"offsets": {
				"from": 1093000,
				"to": 1097000
			},
			"text": " So we're going to look for transparent snark primitives that use pairings."
		},
		{
			"timestamps": {
				"from": "00:18:17,000",
				"to": "00:18:19,000"
			},
			"offsets": {
				"from": 1097000,
				"to": 1099000
			},
			"text": " And we don't really have to look too far."
		},
		{
			"timestamps": {
				"from": "00:18:19,000",
				"to": "00:18:27,000"
			},
			"offsets": {
				"from": 1099000,
				"to": 1107000
			},
			"text": " So Nova, the same authors who wrote Nova, they also authored something called quarks."
		},
		{
			"timestamps": {
				"from": "00:18:27,000",
				"to": "00:18:32,000"
			},
			"offsets": {
				"from": 1107000,
				"to": 1112000
			},
			"text": " And so this is another transparent snark primitive."
		},
		{
			"timestamps": {
				"from": "00:18:32,000",
				"to": "00:18:40,000"
			},
			"offsets": {
				"from": 1112000,
				"to": 1120000
			},
			"text": " And in particular, what's unique about it is they invent some pretty unique polynomial commitment schemes."
		},
		{
			"timestamps": {
				"from": "00:18:40,000",
				"to": "00:18:43,000"
			},
			"offsets": {
				"from": 1120000,
				"to": 1123000
			},
			"text": " They use pairings, but they don't require trusted setup."
		},
		{
			"timestamps": {
				"from": "00:18:43,000",
				"to": "00:18:53,000"
			},
			"offsets": {
				"from": 1123000,
				"to": 1133000
			},
			"text": " And so they can get some significantly better performance than say bulletproofs from a verifier standpoint."
		},
		{
			"timestamps": {
				"from": "00:18:53,000",
				"to": "00:18:55,000"
			},
			"offsets": {
				"from": 1133000,
				"to": 1135000
			},
			"text": " So it's pretty unique."
		},
		{
			"timestamps": {
				"from": "00:18:55,000",
				"to": "00:18:59,000"
			},
			"offsets": {
				"from": 1135000,
				"to": 1139000
			},
			"text": " Again, similar to how Nova was written, they're using Spartan as their IOP."
		},
		{
			"timestamps": {
				"from": "00:18:59,000",
				"to": "00:19:05,000"
			},
			"offsets": {
				"from": 1139000,
				"to": 1145000
			},
			"text": " So basically they take one of their polynomial commitment schemes, the Copa's are Dory, pair it with Spartan, and then now they have a snark."
		},
		{
			"timestamps": {
				"from": "00:19:05,000",
				"to": "00:19:10,000"
			},
			"offsets": {
				"from": 1145000,
				"to": 1150000
			},
			"text": " The nice thing about them, they've got fast and space efficient provers."
		},
		{
			"timestamps": {
				"from": "00:19:10,000",
				"to": "00:19:14,000"
			},
			"offsets": {
				"from": 1150000,
				"to": 1154000
			},
			"text": " That's a property of both the polynomial commitment schemes and the Spartan primitive."
		},
		{
			"timestamps": {
				"from": "00:19:14,000",
				"to": "00:19:20,000"
			},
			"offsets": {
				"from": 1154000,
				"to": 1160000
			},
			"text": " The proofs are, they're a little bit bigger than what you would get out of something like bulletproofs."
		},
		{
			"timestamps": {
				"from": "00:19:20,000",
				"to": "00:19:22,000"
			},
			"offsets": {
				"from": 1160000,
				"to": 1162000
			},
			"text": " But they could be manageable."
		},
		{
			"timestamps": {
				"from": "00:19:22,000",
				"to": "00:19:26,000"
			},
			"offsets": {
				"from": 1162000,
				"to": 1166000
			},
			"text": " And then the nice thing about them too, they have relatively cheap verifiers."
		},
		{
			"timestamps": {
				"from": "00:19:26,000",
				"to": "00:19:28,000"
			},
			"offsets": {
				"from": 1166000,
				"to": 1168000
			},
			"text": " Oh yeah, then just another comment."
		},
		{
			"timestamps": {
				"from": "00:19:28,000",
				"to": "00:19:36,000"
			},
			"offsets": {
				"from": 1168000,
				"to": 1176000
			},
			"text": " There's actually some more research by the same kind of group of authors about Spartan that is used to prove kind of like SIMD computations."
		},
		{
			"timestamps": {
				"from": "00:19:36,000",
				"to": "00:19:41,000"
			},
			"offsets": {
				"from": 1176000,
				"to": 1181000
			},
			"text": " So you have basically our scalar table, right?"
		},
		{
			"timestamps": {
				"from": "00:19:41,000",
				"to": "00:19:45,000"
			},
			"offsets": {
				"from": 1181000,
				"to": 1185000
			},
			"text": " We have one circuit, we have multiple inputs, single input, multiple data."
		},
		{
			"timestamps": {
				"from": "00:19:45,000",
				"to": "00:19:51,000"
			},
			"offsets": {
				"from": 1185000,
				"to": 1191000
			},
			"text": " And so they've got some stuff off the shelf that can seemingly help us with our problem."
		},
		{
			"timestamps": {
				"from": "00:19:51,000",
				"to": "00:19:53,000"
			},
			"offsets": {
				"from": 1191000,
				"to": 1193000
			},
			"text": " So we get really excited about this."
		},
		{
			"timestamps": {
				"from": "00:19:53,000",
				"to": "00:19:59,000"
			},
			"offsets": {
				"from": 1193000,
				"to": 1199000
			},
			"text": " So then we start digging into quarks and we want to use it and we want to try to build some arcs with it."
		},
		{
			"timestamps": {
				"from": "00:19:59,000",
				"to": "00:20:02,000"
			},
			"offsets": {
				"from": 1199000,
				"to": 1202000
			},
			"text": " The first problem that we run into is there's no open source implementation."
		},
		{
			"timestamps": {
				"from": "00:20:02,000",
				"to": "00:20:06,000"
			},
			"offsets": {
				"from": 1202000,
				"to": 1206000
			},
			"text": " So that in itself makes things pretty challenging."
		},
		{
			"timestamps": {
				"from": "00:20:06,000",
				"to": "00:20:10,000"
			},
			"offsets": {
				"from": 1206000,
				"to": 1210000
			},
			"text": " There's no copus nor is there a Dory PC."
		},
		{
			"timestamps": {
				"from": "00:20:10,000",
				"to": "00:20:18,000"
			},
			"offsets": {
				"from": 1210000,
				"to": 1218000
			},
			"text": " Although I was talking that it sounds like there might be a Dory implementation available somewhere as of a couple of days ago."
		},
		{
			"timestamps": {
				"from": "00:20:18,000",
				"to": "00:20:22,000"
			},
			"offsets": {
				"from": 1218000,
				"to": 1222000
			},
			"text": " But I haven't seen it yet."
		},
		{
			"timestamps": {
				"from": "00:20:22,000",
				"to": "00:20:27,000"
			},
			"offsets": {
				"from": 1222000,
				"to": 1227000
			},
			"text": " So knowing that this polynomial commitment scheme is kind of like the primary cost driver for these snarks,"
		},
		{
			"timestamps": {
				"from": "00:20:27,000",
				"to": "00:20:32,000"
			},
			"offsets": {
				"from": 1227000,
				"to": 1232000
			},
			"text": " we implemented the copus PC using the Rust arc works libraries."
		},
		{
			"timestamps": {
				"from": "00:20:32,000",
				"to": "00:20:38,000"
			},
			"offsets": {
				"from": 1232000,
				"to": 1238000
			},
			"text": " And then we ran it to get some benchmarks and kind of get some estimated costs."
		},
		{
			"timestamps": {
				"from": "00:20:38,000",
				"to": "00:20:41,000"
			},
			"offsets": {
				"from": 1238000,
				"to": 1241000
			},
			"text": " And so these are the results for a copus PC."
		},
		{
			"timestamps": {
				"from": "00:20:41,000",
				"to": "00:20:44,000"
			},
			"offsets": {
				"from": 1241000,
				"to": 1244000
			},
			"text": " The one thing that we see in our Prover time now is pretty nice."
		},
		{
			"timestamps": {
				"from": "00:20:44,000",
				"to": "00:20:50,000"
			},
			"offsets": {
				"from": 1244000,
				"to": 1250000
			},
			"text": " That's 565 seconds for the biggest incident size that we would want to prove."
		},
		{
			"timestamps": {
				"from": "00:20:50,000",
				"to": "00:20:53,000"
			},
			"offsets": {
				"from": 1250000,
				"to": 1253000
			},
			"text": " So yeah, that's nice."
		},
		{
			"timestamps": {
				"from": "00:20:53,000",
				"to": "00:20:59,000"
			},
			"offsets": {
				"from": 1253000,
				"to": 1259000
			},
			"text": " The Prover memory requirements, if you have a machine that has 4 gigs of memory, you should be able to run this."
		},
		{
			"timestamps": {
				"from": "00:20:59,000",
				"to": "00:21:01,000"
			},
			"offsets": {
				"from": 1259000,
				"to": 1261000
			},
			"text": " Again, this is our proof size."
		},
		{
			"timestamps": {
				"from": "00:21:01,000",
				"to": "00:21:04,000"
			},
			"offsets": {
				"from": 1261000,
				"to": 1264000
			},
			"text": " So we're in the orders of kilobytes here, right?"
		},
		{
			"timestamps": {
				"from": "00:21:04,000",
				"to": "00:21:09,000"
			},
			"offsets": {
				"from": 1264000,
				"to": 1269000
			},
			"text": " So the small, basically at the biggest incident size we got a proof of about 9 kilobytes."
		},
		{
			"timestamps": {
				"from": "00:21:09,000",
				"to": "00:21:11,000"
			},
			"offsets": {
				"from": 1269000,
				"to": 1271000
			},
			"text": " And then this verify compute."
		},
		{
			"timestamps": {
				"from": "00:21:11,000",
				"to": "00:21:17,000"
			},
			"offsets": {
				"from": 1271000,
				"to": 1277000
			},
			"text": " This is again, we'll see this becomes a big problem."
		},
		{
			"timestamps": {
				"from": "00:21:17,000",
				"to": "00:21:20,000"
			},
			"offsets": {
				"from": 1277000,
				"to": 1280000
			},
			"text": " We're talking about doing elliptic curve arithmetic again."
		},
		{
			"timestamps": {
				"from": "00:21:20,000",
				"to": "00:21:23,000"
			},
			"offsets": {
				"from": 1280000,
				"to": 1283000
			},
			"text": " And then we'll see what the result bulletproofs was doing."
		},
		{
			"timestamps": {
				"from": "00:21:23,000",
				"to": "00:21:28,000"
			},
			"offsets": {
				"from": 1283000,
				"to": 1288000
			},
			"text": " The incident sizes are significantly smaller, but there's still significant work to be done there."
		},
		{
			"timestamps": {
				"from": "00:21:28,000",
				"to": "00:21:35,000"
			},
			"offsets": {
				"from": 1288000,
				"to": 1295000
			},
			"text": " To contrast copus with Dory, which is the other polynomial commitment scheme, Dory takes advantage of some pre-computation"
		},
		{
			"timestamps": {
				"from": "00:21:35,000",
				"to": "00:21:39,000"
			},
			"offsets": {
				"from": 1295000,
				"to": 1299000
			},
			"text": " to reduce this verifier time or this verify compute work even further."
		},
		{
			"timestamps": {
				"from": "00:21:39,000",
				"to": "00:21:45,000"
			},
			"offsets": {
				"from": 1299000,
				"to": 1305000
			},
			"text": " And as a consequence, like their proofs are about three times bigger, so just take these proof sizes, multiply by three,"
		},
		{
			"timestamps": {
				"from": "00:21:45,000",
				"to": "00:21:50,000"
			},
			"offsets": {
				"from": 1305000,
				"to": 1310000
			},
			"text": " and compute is significantly less like we'll see on the next slide."
		},
		{
			"timestamps": {
				"from": "00:21:50,000",
				"to": "00:21:55,000"
			},
			"offsets": {
				"from": 1310000,
				"to": 1315000
			},
			"text": " So quarks look promising, at least the polynomial commitment schemes look promising on paper."
		},
		{
			"timestamps": {
				"from": "00:21:55,000",
				"to": "00:22:02,000"
			},
			"offsets": {
				"from": 1315000,
				"to": 1322000
			},
			"text": " The problem is now, if we want to start, again, running this verifier on Ethereum, the problem is particularly,"
		},
		{
			"timestamps": {
				"from": "00:22:02,000",
				"to": "00:22:10,000"
			},
			"offsets": {
				"from": 1322000,
				"to": 1330000
			},
			"text": " even though there is Alt-Bn128 support, there is no GT exponentiation support."
		},
		{
			"timestamps": {
				"from": "00:22:10,000",
				"to": "00:22:18,000"
			},
			"offsets": {
				"from": 1330000,
				"to": 1338000
			},
			"text": " So, yeah, so that's a significant problem."
		},
		{
			"timestamps": {
				"from": "00:22:18,000",
				"to": "00:22:26,000"
			},
			"offsets": {
				"from": 1338000,
				"to": 1346000
			},
			"text": " And basically, we implemented some GT arithmetic, we simulated the total costs, and we got down to about four million gas"
		},
		{
			"timestamps": {
				"from": "00:22:26,000",
				"to": "00:22:28,000"
			},
			"offsets": {
				"from": 1346000,
				"to": 1348000
			},
			"text": " to do one exponentiation."
		},
		{
			"timestamps": {
				"from": "00:22:28,000",
				"to": "00:22:35,000"
			},
			"offsets": {
				"from": 1348000,
				"to": 1355000
			},
			"text": " And so a whole Dory verify would cost about 125 million gas, or $12,000."
		},
		{
			"timestamps": {
				"from": "00:22:35,000",
				"to": "00:22:37,000"
			},
			"offsets": {
				"from": 1355000,
				"to": 1357000
			},
			"text": " So smaller, but we're still not there yet."
		},
		{
			"timestamps": {
				"from": "00:22:37,000",
				"to": "00:22:40,000"
			},
			"offsets": {
				"from": 1357000,
				"to": 1360000
			},
			"text": " And so now we start asking questions, you know, where do we go?"
		},
		{
			"timestamps": {
				"from": "00:22:40,000",
				"to": "00:22:44,000"
			},
			"offsets": {
				"from": 1360000,
				"to": 1364000
			},
			"text": " Do we really want to use a transparent snark?"
		},
		{
			"timestamps": {
				"from": "00:22:44,000",
				"to": "00:22:48,000"
			},
			"offsets": {
				"from": 1364000,
				"to": 1368000
			},
			"text": " Let's go see what this plonk is all about that everybody's using."
		},
		{
			"timestamps": {
				"from": "00:22:48,000",
				"to": "00:22:51,000"
			},
			"offsets": {
				"from": 1368000,
				"to": 1371000
			},
			"text": " So, you know, plonk's very popular, it's got a ton of support."
		},
		{
			"timestamps": {
				"from": "00:22:51,000",
				"to": "00:22:57,000"
			},
			"offsets": {
				"from": 1371000,
				"to": 1377000
			},
			"text": " Proofs are small, verification is, the cost is known, and really, what we'll see really importantly is,"
		},
		{
			"timestamps": {
				"from": "00:22:57,000",
				"to": "00:23:02,000"
			},
			"offsets": {
				"from": 1377000,
				"to": 1382000
			},
			"text": " plonk is supported, the verifier is supported by pre-compose in Ethereum."
		},
		{
			"timestamps": {
				"from": "00:23:02,000",
				"to": "00:23:08,000"
			},
			"offsets": {
				"from": 1382000,
				"to": 1388000
			},
			"text": " So all of the heavy arithmetic is cheap."
		},
		{
			"timestamps": {
				"from": "00:23:08,000",
				"to": "00:23:14,000"
			},
			"offsets": {
				"from": 1388000,
				"to": 1394000
			},
			"text": " So we dig into plonk, fortunately, like, so popular, there's a lot of high quality open source implementations,"
		},
		{
			"timestamps": {
				"from": "00:23:14,000",
				"to": "00:23:22,000"
			},
			"offsets": {
				"from": 1394000,
				"to": 1402000
			},
			"text": " there's a lot of high quality blog posts, describing plonk, and we see the famous small verify compute,"
		},
		{
			"timestamps": {
				"from": "00:23:22,000",
				"to": "00:23:24,000"
			},
			"offsets": {
				"from": 1402000,
				"to": 1404000
			},
			"text": " small proof size."
		},
		{
			"timestamps": {
				"from": "00:23:24,000",
				"to": "00:23:28,000"
			},
			"offsets": {
				"from": 1404000,
				"to": 1408000
			},
			"text": " The problem with plonk, and this is a known problem too, and this is why everybody is trying to make this"
		},
		{
			"timestamps": {
				"from": "00:23:28,000",
				"to": "00:23:35,000"
			},
			"offsets": {
				"from": 1408000,
				"to": 1415000
			},
			"text": " prove or efficient and try to optimize circuits, is this prove or time and prove or memory is expensive."
		},
		{
			"timestamps": {
				"from": "00:23:35,000",
				"to": "00:23:41,000"
			},
			"offsets": {
				"from": 1415000,
				"to": 1421000
			},
			"text": " So plonk needs to run FFTs, FFTs require, you know, n log n work, and they are also not space-friendly."
		},
		{
			"timestamps": {
				"from": "00:23:41,000",
				"to": "00:23:49,000"
			},
			"offsets": {
				"from": 1421000,
				"to": 1429000
			},
			"text": " And so if we try to prove just a raw two to the 28 size instance, we're looking at, you know, that's 500 minutes."
		},
		{
			"timestamps": {
				"from": "00:23:49,000",
				"to": "00:23:56,000"
			},
			"offsets": {
				"from": 1429000,
				"to": 1436000
			},
			"text": " So we're looking at about eight hours, and you need about three terabytes of memory on your machine to be able to complete"
		},
		{
			"timestamps": {
				"from": "00:23:56,000",
				"to": "00:23:58,000"
			},
			"offsets": {
				"from": 1436000,
				"to": 1438000
			},
			"text": " a proof of the size."
		},
		{
			"timestamps": {
				"from": "00:23:58,000",
				"to": "00:24:06,000"
			},
			"offsets": {
				"from": 1438000,
				"to": 1446000
			},
			"text": " You could do it, you could, you know, go to the cloud, rent a GCP instance, and you can get it down for about $200."
		},
		{
			"timestamps": {
				"from": "00:24:06,000",
				"to": "00:24:11,000"
			},
			"offsets": {
				"from": 1446000,
				"to": 1451000
			},
			"text": " But you're not going to be able to prove this out of the box."
		},
		{
			"timestamps": {
				"from": "00:24:11,000",
				"to": "00:24:14,000"
			},
			"offsets": {
				"from": 1451000,
				"to": 1454000
			},
			"text": " All right, so now we start asking our questions."
		},
		{
			"timestamps": {
				"from": "00:24:14,000",
				"to": "00:24:21,000"
			},
			"offsets": {
				"from": 1454000,
				"to": 1461000
			},
			"text": " We've started getting introspective, we've surveyed some SNARKs, we've flipped a lot between transparent SNARKs"
		},
		{
			"timestamps": {
				"from": "00:24:21,000",
				"to": "00:24:25,000"
			},
			"offsets": {
				"from": 1461000,
				"to": 1465000
			},
			"text": " to trusted set up SNARKs."
		},
		{
			"timestamps": {
				"from": "00:24:25,000",
				"to": "00:24:27,000"
			},
			"offsets": {
				"from": 1465000,
				"to": 1467000
			},
			"text": " What are the important questions here?"
		},
		{
			"timestamps": {
				"from": "00:24:27,000",
				"to": "00:24:32,000"
			},
			"offsets": {
				"from": 1467000,
				"to": 1472000
			},
			"text": " So one thing that really popped up is, why is plonks verifier so much cheaper than, say, dorries verifier?"
		},
		{
			"timestamps": {
				"from": "00:24:32,000",
				"to": "00:24:38,000"
			},
			"offsets": {
				"from": 1472000,
				"to": 1478000
			},
			"text": " And so if you just look at the algorithms that are being used, plonks verifier requires pairings."
		},
		{
			"timestamps": {
				"from": "00:24:38,000",
				"to": "00:24:40,000"
			},
			"offsets": {
				"from": 1478000,
				"to": 1480000
			},
			"text": " Pairings require GT exponentiation."
		},
		{
			"timestamps": {
				"from": "00:24:40,000",
				"to": "00:24:45,000"
			},
			"offsets": {
				"from": 1480000,
				"to": 1485000
			},
			"text": " So pairing should be more expensive than a GT exponentiation, and if you actually do the math,"
		},
		{
			"timestamps": {
				"from": "00:24:45,000",
				"to": "00:24:51,000"
			},
			"offsets": {
				"from": 1485000,
				"to": 1491000
			},
			"text": " it's in dorries PC should cost only about 16 times what, plonks costs."
		},
		{
			"timestamps": {
				"from": "00:24:51,000",
				"to": "00:24:57,000"
			},
			"offsets": {
				"from": 1491000,
				"to": 1497000
			},
			"text": " And so that seems like a reasonable trade-off that somebody would be willing to make, if they don't have to run a trusted setup."
		},
		{
			"timestamps": {
				"from": "00:24:57,000",
				"to": "00:25:04,000"
			},
			"offsets": {
				"from": 1497000,
				"to": 1504000
			},
			"text": " And so the reality is, as we saw, the cost is about 500 times plonks verifier."
		},
		{
			"timestamps": {
				"from": "00:25:04,000",
				"to": "00:25:07,000"
			},
			"offsets": {
				"from": 1504000,
				"to": 1507000
			},
			"text": " And so really it's this pairing check, EIP."
		},
		{
			"timestamps": {
				"from": "00:25:07,000",
				"to": "00:25:14,000"
			},
			"offsets": {
				"from": 1507000,
				"to": 1514000
			},
			"text": " And so one of the big points that we're trying to take away here is we've seen that there are kind of cost competitive transparent SNARK primitives,"
		},
		{
			"timestamps": {
				"from": "00:25:14,000",
				"to": "00:25:20,000"
			},
			"offsets": {
				"from": 1514000,
				"to": 1520000
			},
			"text": " in particular, there are interesting polynomial commitment schemes, these copus schemes, dorries schemes, that could be useful."
		},
		{
			"timestamps": {
				"from": "00:25:20,000",
				"to": "00:25:27,000"
			},
			"offsets": {
				"from": 1520000,
				"to": 1527000
			},
			"text": " But we're not going to be able to run them on Ethereum being that because things are too expensive because they're not supported by, say, precompiles."
		},
		{
			"timestamps": {
				"from": "00:25:27,000",
				"to": "00:25:37,000"
			},
			"offsets": {
				"from": 1527000,
				"to": 1537000
			},
			"text": " And so one of the questions, and this is kind of just like a thought question, right, is Ethereum ecosystem artificially selecting for SNARK primitives with cost they don't reflect reality."
		},
		{
			"timestamps": {
				"from": "00:25:37,000",
				"to": "00:25:46,000"
			},
			"offsets": {
				"from": 1537000,
				"to": 1546000
			},
			"text": " We say Ethereum is driving SNARK research, and it is, and we're seeing a flurry of development, especially for primitives like plonk."
		},
		{
			"timestamps": {
				"from": "00:25:46,000",
				"to": "00:25:51,000"
			},
			"offsets": {
				"from": 1546000,
				"to": 1551000
			},
			"text": " But the reason is it's cheap to verify."
		},
		{
			"timestamps": {
				"from": "00:25:51,000",
				"to": "00:25:57,000"
			},
			"offsets": {
				"from": 1551000,
				"to": 1557000
			},
			"text": " And so the question is, costs aren't reflecting reality."
		},
		{
			"timestamps": {
				"from": "00:25:57,000",
				"to": "00:25:59,000"
			},
			"offsets": {
				"from": 1557000,
				"to": 1559000
			},
			"text": " We want to address this question."
		},
		{
			"timestamps": {
				"from": "00:25:59,000",
				"to": "00:26:06,000"
			},
			"offsets": {
				"from": 1559000,
				"to": 1566000
			},
			"text": " If there are other people who have kind of run into some of the things that come talk to us, we have ideas of how to address this."
		},
		{
			"timestamps": {
				"from": "00:26:06,000",
				"to": "00:26:09,000"
			},
			"offsets": {
				"from": 1566000,
				"to": 1569000
			},
			"text": " Yeah, with the last minute, where do we go next?"
		},
		{
			"timestamps": {
				"from": "00:26:09,000",
				"to": "00:26:11,000"
			},
			"offsets": {
				"from": 1569000,
				"to": 1571000
			},
			"text": " Right, so we've got all over the place."
		},
		{
			"timestamps": {
				"from": "00:26:11,000",
				"to": "00:26:12,000"
			},
			"offsets": {
				"from": 1571000,
				"to": 1572000
			},
			"text": " We've surveyed a bunch of SNARKs."
		},
		{
			"timestamps": {
				"from": "00:26:12,000",
				"to": "00:26:16,000"
			},
			"offsets": {
				"from": 1572000,
				"to": 1576000
			},
			"text": " Actually, there's a ton of SNARKs in practice, right, and we look at all of these."
		},
		{
			"timestamps": {
				"from": "00:26:16,000",
				"to": "00:26:21,000"
			},
			"offsets": {
				"from": 1576000,
				"to": 1581000
			},
			"text": " This is, this was our path, but, you know, there's a whole bunch of places we can go."
		},
		{
			"timestamps": {
				"from": "00:26:21,000",
				"to": "00:26:33,000"
			},
			"offsets": {
				"from": 1581000,
				"to": 1593000
			},
			"text": " The other point here is SNARKs, generally we think of them as proving kind of arbitrary programs, NP complete, or NP statements that power as a cost."
		},
		{
			"timestamps": {
				"from": "00:26:33,000",
				"to": "00:26:38,000"
			},
			"offsets": {
				"from": 1593000,
				"to": 1598000
			},
			"text": " We have other proving systems that have cheaper costs, signatures are one such proving system."
		},
		{
			"timestamps": {
				"from": "00:26:38,000",
				"to": "00:26:43,000"
			},
			"offsets": {
				"from": 1598000,
				"to": 1603000
			},
			"text": " So we sell away from the land of SNARKs to the land of homomorphic signatures."
		},
		{
			"timestamps": {
				"from": "00:26:43,000",
				"to": "00:26:48,000"
			},
			"offsets": {
				"from": 1603000,
				"to": 1608000
			},
			"text": " And so what a homomorphic signature does is it basically allows you to sign data."
		},
		{
			"timestamps": {
				"from": "00:26:48,000",
				"to": "00:26:57,000"
			},
			"offsets": {
				"from": 1608000,
				"to": 1617000
			},
			"text": " And then if you like signed two messages, you can add those two messages together, and the result is a signed message for the sum of the two underlying messages."
		},
		{
			"timestamps": {
				"from": "00:26:57,000",
				"to": "00:26:59,000"
			},
			"offsets": {
				"from": 1617000,
				"to": 1619000
			},
			"text": " So it's a pretty cool primitive."
		},
		{
			"timestamps": {
				"from": "00:26:59,000",
				"to": "00:27:04,000"
			},
			"offsets": {
				"from": 1619000,
				"to": 1624000
			},
			"text": " I haven't really seen it used much in practice, but we have a unique application here on blockchain."
		},
		{
			"timestamps": {
				"from": "00:27:04,000",
				"to": "00:27:10,000"
			},
			"offsets": {
				"from": 1624000,
				"to": 1630000
			},
			"text": " And so we can take advantage of that and run this reference scheme."
		},
		{
			"timestamps": {
				"from": "00:27:10,000",
				"to": "00:27:16,000"
			},
			"offsets": {
				"from": 1630000,
				"to": 1636000
			},
			"text": " And basically the bottom line is we get small proofs, small verify time, similar to Planck."
		},
		{
			"timestamps": {
				"from": "00:27:16,000",
				"to": "00:27:22,000"
			},
			"offsets": {
				"from": 1636000,
				"to": 1642000
			},
			"text": " These costs are about the same cost of aggregating just regular bill signatures, so it looked like a arithmetic."
		},
		{
			"timestamps": {
				"from": "00:27:22,000",
				"to": "00:27:27,000"
			},
			"offsets": {
				"from": 1642000,
				"to": 1647000
			},
			"text": " And we can get something done for less than $30."
		},
		{
			"timestamps": {
				"from": "00:27:27,000",
				"to": "00:27:29,000"
			},
			"offsets": {
				"from": 1647000,
				"to": 1649000
			},
			"text": " Quote, I like."
		},
		{
			"timestamps": {
				"from": "00:27:29,000",
				"to": "00:27:32,000"
			},
			"offsets": {
				"from": 1649000,
				"to": 1652000
			},
			"text": " It's worth thinking about."
		},
		{
			"timestamps": {
				"from": "00:27:32,000",
				"to": "00:27:37,000"
			},
			"offsets": {
				"from": 1652000,
				"to": 1657000
			},
			"text": " Again, this is we are edge of node semiotic labs for core developers for the graph."
		},
		{
			"timestamps": {
				"from": "00:27:37,000",
				"to": "00:27:40,000"
			},
			"offsets": {
				"from": 1657000,
				"to": 1660000
			},
			"text": " I'm with semiotic AI."
		},
		{
			"timestamps": {
				"from": "00:27:40,000",
				"to": "00:27:42,000"
			},
			"offsets": {
				"from": 1660000,
				"to": 1662000
			},
			"text": " We're looking for people who are interested in these types of problems."
		},
		{
			"timestamps": {
				"from": "00:27:42,000",
				"to": "00:27:48,000"
			},
			"offsets": {
				"from": 1662000,
				"to": 1668000
			},
			"text": " We're also looking for people who are interested in, you know, AI reinforcement learning, all kinds of good stuff."
		},
		{
			"timestamps": {
				"from": "00:27:48,000",
				"to": "00:27:49,000"
			},
			"offsets": {
				"from": 1668000,
				"to": 1669000
			},
			"text": " We're looking for people."
		},
		{
			"timestamps": {
				"from": "00:27:49,000",
				"to": "00:27:50,000"
			},
			"offsets": {
				"from": 1669000,
				"to": 1670000
			},
			"text": " This was interesting."
		},
		{
			"timestamps": {
				"from": "00:27:50,000",
				"to": "00:27:51,000"
			},
			"offsets": {
				"from": 1670000,
				"to": 1671000
			},
			"text": " Reach out."
		},
		{
			"timestamps": {
				"from": "00:27:51,000",
				"to": "00:27:52,000"
			},
			"offsets": {
				"from": 1671000,
				"to": 1672000
			},
			"text": " Thank you."
		},
		{
			"timestamps": {
				"from": "00:27:52,000",
				"to": "00:27:57,000"
			},
			"offsets": {
				"from": 1672000,
				"to": 1677000
			},
			"text": " [Applause]"
		},
		{
			"timestamps": {
				"from": "00:27:57,000",
				"to": "00:28:02,000"
			},
			"offsets": {
				"from": 1677000,
				"to": 1682000
			},
			"text": " [Applause]"
		},
		{
			"timestamps": {
				"from": "00:28:02,000",
				"to": "00:28:07,000"
			},
			"offsets": {
				"from": 1682000,
				"to": 1687000
			},
			"text": " [Applause]"
		},
		{
			"timestamps": {
				"from": "00:28:07,000",
				"to": "00:28:12,000"
			},
			"offsets": {
				"from": 1687000,
				"to": 1692000
			},
			"text": " [Applause]"
		}
	]
}
